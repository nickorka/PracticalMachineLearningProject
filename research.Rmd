---
title: "Practical Machine Learining Class Project"
author: "Nick Orka"
date: "3/3/2020"
output: 
    html_document:
        fig_height: 8
        fig_width: 8

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. A goal of the project is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants and to predict the manner in which they did the exercise. This is the "classe" variable in the training set.

## Data preprocessing
The training data for this project are available here:  
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:  
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source:   http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har. 
```{r, cache=T, echo=F, warning=F}
library(caret)
library(corrplot)
library(rattle)
library(randomForest)
# devtools::install_github("MI2DataLab/randomForestExplainer")
library(randomForestExplainer)
```
```{r, cache = T, echo = F}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method="curl")
}
training <- read.csv("./data/pml-training.csv")
testing <- read.csv("./data/pml-testing.csv")
```
### Data summary
The initial data have NA data that required to be cleaned:
```{r, cache=T}
dim(training)
dim(testing)
```
### Cleaning data
Cleaned data:
```{r, cache=T}
var_names <- names(training)
naNames <- names(training[, colSums(is.na(training)) > 0])
var_names <- var_names[!var_names %in% naNames]
var_names <- var_names[!grepl("X|timestamp|window", var_names)]
training <- training[, var_names]
classe <- training$classe
training <- training[, sapply(training, is.numeric)]
var_names <- names(training)
training$classe <- classe
testing <- testing[, var_names]
dim(training)
dim(testing)
```
### Create validation dataset
```{r, cache=T}
set.seed(34562)
isTrain <- createDataPartition(training$classe, p = .7, list = F)
validating <- training[-isTrain, ]
training <- training[isTrain,]
dim(validating)
dim(training)
```
## Prediction model
```{r, cache=T}
control <- caret::trainControl(method = "cv", 5)
model <- caret::train(classe ~ ., data = training, method = "rf", trControl = control, ntree = 250, localImp = TRUE)
model
```
Then, we estimate the performance of the model on the validation data set.  
```{r, cache = T}
p <- predict(model, validating)
confusionMatrix(validating$classe, p)
```
```{r, cache = T}
accuracy <- postResample(p, validating$classe)
accuracy
oose <- 1 - as.numeric(confusionMatrix(validating$classe, p)$overall[1])
oose
```
So, the estimated accuracy of the model is 99.17% and the estimated out-of-sample error is 0.83%.
I have chosen Random forest due to several factors: 1) you can get feature importance; 2) it is a robust method; 3) you need not care about distribution; 4) if you alter your RF well, it will not be very time-consuming.

## Predicting for Test Data Set
Now, we apply the model to the original testing data set downloaded from the data source. 
```{r, cache = T}
result <- predict(model, testing)
result
```  

## Appendix: Figures
```{r, cache=T, echo=F}
min_depth_frame <- min_depth_distribution(model$finalModel)
importance_frame <- measure_importance(model$finalModel)
vars <- important_variables(model$finalModel, k = 5, measures = c("mean_min_depth", "no_of_trees"))
#interactions_frame <- min_depth_interactions(model$finalModel, vars)
```

### 1. Variable importance
```{r, cache=T, echo=F}
varImpPlot(model$finalModel, main = "Variable Importance of RF model")
plot_multi_way_importance(importance_frame, y_measure = "accuracy_decrease", x_measure = "mean_min_depth", size_measure = "p_value", no_of_labels = 5)
plot_importance_ggpairs(importance_frame)
```

### 2. Correlation Matrix Visualization  

```{r, cache = T, echo=F}
corrPlot <- cor(training[, -(length(var_names) + 1)])
corrplot(corrPlot, method="color")
```

### 3. Decision Tree Visualization

```{r, cache = T, echo=F}
modFitTree <- train(classe ~ ., data=training, method="rpart")
fancyRpartPlot(modFitTree$finalModel)
plot_min_depth_distribution(min_depth_frame)
```


